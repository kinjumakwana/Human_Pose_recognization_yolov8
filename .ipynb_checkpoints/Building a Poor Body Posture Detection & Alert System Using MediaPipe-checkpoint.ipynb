{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed588825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://learnopencv.com/building-a-body-posture-analysis-system-using-mediapipe/\n",
    "# https://github.com/spmallick/learnopencv/tree/master/Posture-analysis-system-using-MediaPipe-Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637f42ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Obtaining dependency information for mediapipe from https://files.pythonhosted.org/packages/d4/22/7bf6bfff8a01ac38d9d744d07f90697997eab709e9a5ad1e0301202acb06/mediapipe-0.10.3-cp39-cp39-win_amd64.whl.metadata\n",
      "  Using cached mediapipe-0.10.3-cp39-cp39-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting absl-py (from mediapipe)\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from mediapipe) (22.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from mediapipe) (3.7.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from mediapipe) (1.25.2)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Obtaining dependency information for opencv-contrib-python from https://files.pythonhosted.org/packages/05/33/5a6436146bda09c69decc456cfb54f41d52fbcf558fe91e6df7bdde6cce0/opencv_contrib_python-4.8.0.76-cp37-abi3-win_amd64.whl.metadata\n",
      "  Using cached opencv_contrib_python-4.8.0.76-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Using cached sounddevice-0.4.6-py3-none-win_amd64.whl (199 kB)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from matplotlib->mediapipe) (6.0.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->mediapipe) (3.16.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\baps\\anaconda3\\envs\\tf\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Using cached mediapipe-0.10.3-cp39-cp39-win_amd64.whl (50.2 MB)\n",
      "Using cached opencv_contrib_python-4.8.0.76-cp37-abi3-win_amd64.whl (44.8 MB)\n",
      "Installing collected packages: opencv-contrib-python, absl-py, sounddevice, mediapipe\n",
      "Successfully installed absl-py-1.4.0 mediapipe-0.10.3 opencv-contrib-python-4.8.0.76 sounddevice-0.4.6\n"
     ]
    }
   ],
   "source": [
    "# !pip install MediaPipe\n",
    "!pip install mediapipe --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e99783ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import math as m\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3642ec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilize medipipe selfie segmentation class.\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af352580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance =  sqrt{(x2 - x1)^2+(y2 - y1)^2}\n",
    "def findDistance(x1, y1, x2, y2):\n",
    "    dist = m.sqrt((x2-x1)**2+(y2-y1)**2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "520dae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  torso line connects the hip and the shoulder, where the hip is considered a pivotal point\n",
    "# P1(x1, y1): shoulder\n",
    "# P2(x2, y2): eye\n",
    "# P3(x3, y3): any point on the vertical axis passing through P1\n",
    "    \n",
    "# Calculate angle.\n",
    "def findAngle(x1, y1, x2, y2):\n",
    "    theta = m.acos( (y2 -y1)*(-y1) / (m.sqrt(\n",
    "        (x2 - x1)**2 + (y2 - y1)**2 ) * y1) )\n",
    "    degree = int(180/m.pi)*theta\n",
    "    return degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cd1c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendWarning(x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bf38054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize frame counters.\n",
    "good_frames = 0\n",
    "bad_frames  = 0\n",
    " \n",
    "# Font type.\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    " \n",
    "# Colors.\n",
    "blue = (255, 127, 0)\n",
    "red = (50, 50, 255)\n",
    "green = (127, 255, 0)\n",
    "dark_blue = (127, 20, 0)\n",
    "light_green = (127, 233, 100)\n",
    "yellow = (0, 255, 255)\n",
    "pink = (255, 0, 255)\n",
    " \n",
    "# Initialize mediapipe pose class.\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9eef5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For webcam input replace file name with 0.\n",
    "# file_name = 's1.mp4'\n",
    "file_name = 0\n",
    "\n",
    "cap = cv2.VideoCapture(file_name)\n",
    "\n",
    "# Meta.\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_size = (width, height)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Video writer.\n",
    "video_output = cv2.VideoWriter('output3.mp4', fourcc, fps, frame_size)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "000efd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing..\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from left to right.\n",
      "Object is moving from right to left.\n",
      "Object is moving from left to right.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Process the image.\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m keypoints \u001b[38;5;241m=\u001b[39m \u001b[43mpose\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Check if landmarks were detected.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keypoints\u001b[38;5;241m.\u001b[39mpose_landmarks:\n\u001b[0;32m     24\u001b[0m     \n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# You can use the x-coordinate of a landmark, for example, the nose.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\mediapipe\\python\\solutions\\pose.py:185\u001b[0m, in \u001b[0;36mPose.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\mediapipe\\python\\solution_base.py:365\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    359\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    361\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    362\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    363\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 365\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    368\u001b[0m solution_outputs \u001b[38;5;241m=\u001b[39m collections\u001b[38;5;241m.\u001b[39mnamedtuple(\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolutionOutputs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Processing..')\n",
    "prev_nose_x = None  # Initialize the previous nose position\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Capture frames.\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"Null.Frames\")\n",
    "        break\n",
    "        \n",
    "    # Get fps.\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # Get height and width.\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Convert the BGR image to RGB.\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the image.\n",
    "    keypoints = pose.process(image)\n",
    "    \n",
    "    # Check if landmarks were detected.\n",
    "    if keypoints.pose_landmarks:\n",
    "        \n",
    "        # You can use the x-coordinate of a landmark, for example, the nose.\n",
    "        nose_x = int(keypoints.pose_landmarks.landmark[mp_pose.PoseLandmark.NOSE].x * w)\n",
    "    \n",
    "                # Check if this is not the first frame.\n",
    "        if prev_nose_x is not None:\n",
    "            # Compare the current nose position with the previous position.\n",
    "            if nose_x > prev_nose_x:\n",
    "                print(\"Object is moving from left to right.\")\n",
    "                # Handle this case by updating the nose_x coordinate accordingly.\n",
    "                # You may also update other keypoints as needed.\n",
    "            elif nose_x < prev_nose_x:\n",
    "                print(\"Object is moving from right to left.\")\n",
    "                # Handle this case by updating the nose_x coordinate accordingly.\n",
    "                # You may also update other keypoints as needed.\n",
    "\n",
    "        # Store the current nose position as the previous position for the next frame.\n",
    "        prev_nose_x = nose_x\n",
    "        \n",
    "        # Convert the image back to BGR.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Use lm and lmPose as representative of the following methods.\n",
    "        lm = keypoints.pose_landmarks\n",
    "        lmPose = mp_pose.PoseLandmark\n",
    "\n",
    "        # Acquire the landmark coordinates.\n",
    "        # Once aligned properly, left or right should not be a concern.      \n",
    "        # Left shoulder.\n",
    "        l_shldr_x = int(lm.landmark[lmPose.LEFT_SHOULDER].x * w)\n",
    "        l_shldr_y = int(lm.landmark[lmPose.LEFT_SHOULDER].y * h)\n",
    "        # Right shoulder\n",
    "        r_shldr_x = int(lm.landmark[lmPose.RIGHT_SHOULDER].x * w)\n",
    "        r_shldr_y = int(lm.landmark[lmPose.RIGHT_SHOULDER].y * h)\n",
    "        # Left ear.\n",
    "        l_ear_x = int(lm.landmark[lmPose.LEFT_EAR].x * w)\n",
    "        l_ear_y = int(lm.landmark[lmPose.LEFT_EAR].y * h)\n",
    "        # Left hip.\n",
    "        l_hip_x = int(lm.landmark[lmPose.LEFT_HIP].x * w)\n",
    "        l_hip_y = int(lm.landmark[lmPose.LEFT_HIP].y * h)\n",
    "\n",
    "        # Calculate distance between left shoulder and right shoulder points.\n",
    "        offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n",
    "\n",
    "        # Assist to align the camera to point at the side view of the person.\n",
    "        # Offset threshold 30 is based on results obtained from analysis over 100 samples.\n",
    "        if offset < 100:\n",
    "            cv2.putText(image, str(int(offset)) + ' Aligned', (w - 150, 30), font, 0.9, green, 2)\n",
    "        else:\n",
    "            cv2.putText(image, str(int(offset)) + ' Not Aligned', (w - 150, 30), font, 0.9, red, 2)\n",
    "\n",
    "        # Calculate angles.\n",
    "        neck_inclination = findAngle(l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)\n",
    "        torso_inclination = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)\n",
    "\n",
    "        # Draw landmarks.\n",
    "        cv2.circle(image, (l_shldr_x, l_shldr_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_ear_x, l_ear_y), 7, yellow, -1)\n",
    "\n",
    "        # Let's take y - coordinate of P3 100px above x1,  for display elegance.\n",
    "        # Although we are taking y = 0 while calculating angle between P1,P2,P3.\n",
    "        cv2.circle(image, (l_shldr_x, l_shldr_y - 100), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_shldr_x, r_shldr_y), 7, pink, -1)\n",
    "        cv2.circle(image, (l_hip_x, l_hip_y), 7, yellow, -1)\n",
    "\n",
    "        # Similarly, here we are taking y - coordinate 100px above x1. Note that\n",
    "        # you can take any value for y, not necessarily 100 or 200 pixels.\n",
    "        cv2.circle(image, (l_hip_x, l_hip_y - 100), 7, yellow, -1)\n",
    "\n",
    "        # Put text, Posture and angle inclination.\n",
    "        # Text string for display.\n",
    "        angle_text_string = 'Neck : ' + str(int(neck_inclination)) + '  Torso : ' + str(int(torso_inclination))\n",
    "\n",
    "        # Determine whether good posture or bad posture.\n",
    "        # The threshold angles have been set based on intuition.\n",
    "        if neck_inclination < 40 and torso_inclination < 10:\n",
    "            bad_frames = 0\n",
    "            good_frames += 1\n",
    "\n",
    "            cv2.putText(image, angle_text_string, (10, 30), font, 0.9, light_green, 2)\n",
    "            cv2.putText(image, str(int(neck_inclination)), (l_shldr_x + 10, l_shldr_y), font, 0.9, light_green, 2)\n",
    "            cv2.putText(image, str(int(torso_inclination)), (l_hip_x + 10, l_hip_y), font, 0.9, light_green, 2)\n",
    "\n",
    "            # Join landmarks.\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), green, 4)\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_shldr_x, l_shldr_y - 100), green, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), green, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_hip_x, l_hip_y - 100), green, 4)\n",
    "\n",
    "        else:\n",
    "            good_frames = 0\n",
    "            bad_frames += 1\n",
    "\n",
    "            cv2.putText(image, angle_text_string, (10, 30), font, 0.9, red, 2)\n",
    "            cv2.putText(image, str(int(neck_inclination)), (l_shldr_x + 10, l_shldr_y), font, 0.9, red, 2)\n",
    "            cv2.putText(image, str(int(torso_inclination)), (l_hip_x + 10, l_hip_y), font, 0.9, red, 2)\n",
    "\n",
    "            # Join landmarks.\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), red, 4)\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_shldr_x, l_shldr_y - 100), red, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), red, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_hip_x, l_hip_y - 100), red, 4)\n",
    "\n",
    "        # Calculate the time of remaining in a particular posture.\n",
    "        good_time = (1 / fps) * good_frames\n",
    "        bad_time =  (1 / fps) * bad_frames\n",
    "        \n",
    "        font_scale = 1.5\n",
    "        \n",
    "        # Pose time.\n",
    "        if good_time > 0:\n",
    "            time_string_good = 'Good Posture Time : ' + str(round(good_time, 1)) + 's'\n",
    "            cv2.putText(image, time_string_good, (10, h - 20), font, font_scale, green, 3)\n",
    "        else:\n",
    "            time_string_bad = 'Bad Posture Time : ' + str(round(bad_time, 1)) + 's'\n",
    "            cv2.putText(image, time_string_bad, (10, h - 20), font, font_scale, red, 3)\n",
    "\n",
    "        # If you stay in bad posture for more than 3 minutes (180s) send an alert.\n",
    "        if bad_time > 180:\n",
    "            sendWarning()\n",
    "        # Write frames.\n",
    "        video_output.write(image)\n",
    "print('Finished.')\n",
    "cap.release()\n",
    "video_output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08877530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://w7.pngwing.com/pngs/261/122/png-transparent-running-sport-computer-icons-scape-running-man-miscellaneous-tshirt-physical-fitness.png locally at png-transparent-running-sport-computer-icons-scape-running-man-miscellaneous-tshirt-physical-fitness.png\n",
      "image 1/1 C:\\Users\\BAPS\\Documents\\Pose_estimation\\png-transparent-running-sport-computer-icons-scape-running-man-miscellaneous-tshirt-physical-fitness.png: 640x448 1 person, 250.3ms\n",
      "Speed: 5.4ms preprocess, 250.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.57153     0.18543]\n",
      " [    0.59531     0.17075]\n",
      " [     0.5532     0.17274]\n",
      " [    0.63688     0.18092]\n",
      " [    0.53537     0.18756]\n",
      " [     0.7178     0.27027]\n",
      " [    0.48701     0.29362]\n",
      " [    0.80418     0.35368]\n",
      " [      0.434     0.39855]\n",
      " [    0.74929     0.40223]\n",
      " [    0.45143     0.38739]\n",
      " [    0.67841     0.50748]\n",
      " [    0.54712     0.51218]\n",
      " [    0.63572     0.69112]\n",
      " [    0.60602     0.67174]\n",
      " [    0.62602     0.85577]\n",
      " [    0.73923     0.80932]]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "# Predict with the model\n",
    "results = model('https://w7.pngwing.com/pngs/261/122/png-transparent-running-sport-computer-icons-scape-running-man-miscellaneous-tshirt-physical-fitness.png') \n",
    "\n",
    "# Extract keypoint\n",
    "result_keypoint = results[0].keypoints.xyn.cpu().numpy()[0]\n",
    "\n",
    "print(result_keypoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e200817d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
